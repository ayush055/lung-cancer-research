{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install classification-models-3D"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-12T00:01:21.984972Z","iopub.status.busy":"2022-04-12T00:01:21.984432Z","iopub.status.idle":"2022-04-12T00:01:29.009101Z","shell.execute_reply":"2022-04-12T00:01:29.008219Z","shell.execute_reply.started":"2022-04-12T00:01:21.98486Z"},"trusted":true},"outputs":[],"source":["import math, re, os, gc\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from kaggle_datasets import KaggleDatasets\n","from tensorflow import keras\n","from functools import partial\n","from sklearn.model_selection import train_test_split\n","import tensorflow_addons as tfa\n","import matplotlib.ticker as mtick\n","import tensorflow.experimental.numpy as tnp"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:34.899374Z","iopub.status.busy":"2022-04-12T00:01:34.899072Z","iopub.status.idle":"2022-04-12T00:01:43.083314Z","shell.execute_reply":"2022-04-12T00:01:43.082687Z","shell.execute_reply.started":"2022-04-12T00:01:34.899342Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:53.443638Z","iopub.status.busy":"2022-04-12T00:01:53.443354Z","iopub.status.idle":"2022-04-12T00:01:53.450142Z","shell.execute_reply":"2022-04-12T00:01:53.449542Z","shell.execute_reply.started":"2022-04-12T00:01:53.443602Z"},"trusted":true},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","def seed_all(s):\n","    random.seed(s)\n","    np.random.seed(s)\n","    tf.random.set_seed(s)\n","    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n","    os.environ['PYTHONHASHSEED'] = str(s)\n","    \n","seed = 42"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:53.451511Z","iopub.status.busy":"2022-04-12T00:01:53.451284Z","iopub.status.idle":"2022-04-12T00:01:53.464211Z","shell.execute_reply":"2022-04-12T00:01:53.463305Z","shell.execute_reply.started":"2022-04-12T00:01:53.451485Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 8 * strategy.num_replicas_in_sync # Number of the batch size"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:53.465737Z","iopub.status.busy":"2022-04-12T00:01:53.465505Z","iopub.status.idle":"2022-04-12T00:01:53.477142Z","shell.execute_reply":"2022-04-12T00:01:53.476286Z","shell.execute_reply.started":"2022-04-12T00:01:53.46571Z"},"trusted":true},"outputs":[],"source":["PIXEL_MEAN = 0.25\n","MIN_BOUND = -1000.0\n","MAX_BOUND = 400.0\n","\n","from scipy import ndimage\n","\n","def normalize(image):\n","    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n","#     image /= 2048\n","#     image[image>1] = 1.\n","#     image[image<0] = 0.\n","    image = tf.multiply(image, tf.cast(tf.math.greater(image, tf.constant([0], dtype=tf.float32)), tf.float32))\n","    image = tf.multiply(image, tf.cast(tf.math.less(image, tf.constant([1], dtype=tf.float32)), tf.float32))\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:53.493331Z","iopub.status.busy":"2022-04-12T00:01:53.493018Z","iopub.status.idle":"2022-04-12T00:01:53.525316Z","shell.execute_reply":"2022-04-12T00:01:53.524516Z","shell.execute_reply.started":"2022-04-12T00:01:53.4933Z"},"trusted":true},"outputs":[],"source":["# DO NOT RUN\n","\n","IMG_DEPTH = 128\n","IMG_HEIGHT = 512\n","IMG_WIDTH = 512\n","IMG_CHANNELS = 3\n","\n","MIN_BOUND = -1000.0\n","MAX_BOUND = 400.0\n","CLASSES = [0, 1, 2, 3, 4]\n","\n","feature_description = {\n","    'scan_id': tf.io.FixedLenFeature([], tf.string),\n","    'height': tf.io.FixedLenFeature([], tf.int64),\n","    'width': tf.io.FixedLenFeature([], tf.int64),\n","    'num_channels': tf.io.FixedLenFeature([], tf.int64),\n","    'image': tf.io.FixedLenFeature([], tf.string),\n","    'label': tf.io.FixedLenFeature([], tf.int64),\n","    'internalStructure': tf.io.FixedLenFeature([], tf.int64),\n","    'calcification': tf.io.FixedLenFeature([], tf.int64),\n","    'sphericity': tf.io.FixedLenFeature([], tf.int64),\n","    'margin': tf.io.FixedLenFeature([], tf.int64),\n","    'lobulation': tf.io.FixedLenFeature([], tf.int64),\n","    'spiculation': tf.io.FixedLenFeature([], tf.int64),\n","    'texture': tf.io.FixedLenFeature([], tf.int64),\n","}\n","\n","feature_list_description = {\n","    'annotation_indices': tf.io.FixedLenSequenceFeature([], tf.int64),\n","}\n","\n","def _parse_image_function(example_proto):\n","  # Parse the input tf.Example proto using the dictionary above.\n","    feature, features_list = tf.io.parse_single_sequence_example(\n","                            example_proto, \n","                            sequence_features=feature_list_description,                                                   \n","                            context_features=feature_description\n","                        )\n","#     single_example = tf.io.parse_single_example(example_proto, image_feature_description)\n","    scan_id = feature['scan_id']\n","    img_height = feature['height']\n","    img_width = feature['width']\n","    num_images = feature['num_channels']\n","    label = feature['label']\n","    internalStructure = feature['internalStructure']\n","    calcification = feature['calcification']\n","    sphericity = feature['sphericity']\n","    margin = feature['margin']\n","    lobulation = feature['lobulation']\n","    spiculation = feature['spiculation']\n","    texture = feature['texture']\n","    \n","    img_bytes =  tf.io.parse_tensor(feature['image'], out_type=tf.float32) #tf.io.decode_raw(feature['image'],out_type='double')\n","    img_array = tf.reshape(img_bytes, (num_images, img_height, img_width))\n","    \n","    annotation_indices = features_list['annotation_indices']\n","    \n","    struct = {\n","        'scan_id': scan_id,\n","        'height': img_height,\n","        'width': img_width,\n","        'num_images': num_images,\n","        'img': img_array,\n","        'label': label,\n","        'internalStructure': internalStructure,\n","        'calcification': calcification,\n","        'sphericity': sphericity,\n","        'margin': margin,\n","        'lobulation': lobulation,\n","        'spiculation': spiculation,\n","        'texture': texture,\n","        'annotation_indices': annotation_indices,\n","    }\n","\n","#     img_array = tf.stack([img_array, img_array, img_array], axis=-1)\n","    \n","#     img_array = tf.reshape(img_array, [IMG_DEPTH, IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS])\n","    \n","    img_array = tf.reshape(img_array, [32, 64, 64, 1])\n","#     img_array = zero_center(normalize(img_array))\n","#     img_array = resize_volume(normalize(img_array), img_width, img_height, num_images)\n","    \n","    label = tf.cast(label, tf.int32)\n","    \n","#     if label < 3:\n","#         label = 0\n","#     elif label > 3:\n","#         label = 1\n","#     else:\n","#         label = 2\n","        \n","    label = tf.one_hot(label - 1, depth=len(CLASSES))\n","                         \n","    return {'image': img_array, \n","            'internalStructure': internalStructure,\n","            'calcification': calcification,\n","            'sphericity': sphericity,\n","            'margin': margin,\n","            'lobulation': lobulation,\n","            'spiculation': spiculation,\n","            'texture': texture}, label\n","\n","def _parse_image_function_testing(example_proto):\n","  # Parse the input tf.Example proto using the dictionary above.\n","    feature, features_list = tf.io.parse_single_sequence_example(\n","                            example_proto, \n","                            sequence_features=feature_list_description,                                                   \n","                            context_features=feature_description\n","                        )\n","#     single_example = tf.io.parse_single_example(example_proto, image_feature_description)\n","    scan_id = feature['scan_id']\n","    img_height = feature['height']\n","    img_width = feature['width']\n","    num_images = feature['num_channels']\n","    label = feature['label']\n","    internalStructure = feature['internalStructure']\n","    calcification = feature['calcification']\n","    sphericity = feature['sphericity']\n","    margin = feature['margin']\n","    lobulation = feature['lobulation']\n","    spiculation = feature['spiculation']\n","    texture = feature['texture']\n","    \n","    img_bytes =  tf.io.parse_tensor(feature['image'], out_type=tf.float32) #tf.io.decode_raw(feature['image'],out_type='double')\n","    img_array = tf.reshape(img_bytes, (num_images, img_height, img_width))\n","    \n","    annotation_indices = features_list['annotation_indices']\n","    \n","    struct = {\n","        'scan_id': scan_id,\n","        'height': img_height,\n","        'width': img_width,\n","        'num_images': num_images,\n","        'img': img_array,\n","        'label': label,\n","        'internalStructure': internalStructure,\n","        'calcification': calcification,\n","        'sphericity': sphericity,\n","        'margin': margin,\n","        'lobulation': lobulation,\n","        'spiculation': spiculation,\n","        'texture': texture,\n","        'annotation_indices': annotation_indices,\n","    }\n","\n","#     img_array = tf.stack([img_array, img_array, img_array], axis=-1)\n","    \n","#     img_array = tf.reshape(img_array, [IMG_DEPTH, IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS])\n","    \n","    img_array = tf.reshape(img_array, [32, 64, 64, 1])\n","#     img_array = zero_center(normalize(img_array))\n","#     img_array = resize_volume(normalize(img_array), img_width, img_height, num_images)\n","    \n","    label = tf.cast(label, tf.int32)\n","    \n","#     if label < 3:\n","#         label = 0\n","#     elif label > 3:\n","#         label = 1\n","#     else:\n","#         label = 2\n","        \n","    label = tf.one_hot(label - 1, depth=len(CLASSES))\n","                         \n","    return {'image': img_array, \n","            'internalStructure': internalStructure,\n","            'calcification': calcification,\n","            'sphericity': sphericity,\n","            'margin': margin,\n","            'lobulation': lobulation,\n","            'spiculation': spiculation,\n","            'texture': texture,\n","            'scan_id': scan_id,\n","            'annotation_indices': annotation_indices,\n","            }, label\n","\n","def read_tf_dataset(storage_file_path):\n","    encoded_image_dataset = tf.data.TFRecordDataset(storage_file_path, compression_type=\"GZIP\")\n","    parsed_image_dataset = encoded_image_dataset.map(_parse_image_function)\n","    return parsed_image_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:53.529056Z","iopub.status.busy":"2022-04-12T00:01:53.52831Z","iopub.status.idle":"2022-04-12T00:01:53.574389Z","shell.execute_reply":"2022-04-12T00:01:53.573255Z","shell.execute_reply.started":"2022-04-12T00:01:53.529013Z"},"trusted":true},"outputs":[],"source":["# Augmentations - Source: https://www.kaggle.com/code/sreevishnudamodaran/rsna-3d-clahe-voxels-tpu-3d-augmentations/notebook\n","\n","from tensorflow_addons.image import utils as img_utils\n","\n","FLIP = 0.5 # @params: probability\n","CONTRAST = (0.3, 1.3, 0.5) # @params: (minval, maxval, probability)\n","BRIGHTNESS = (0.4, 0.4) # @params: (delta, probability)\n","GAMMA = (0.8, 1.2, 0.25) # @params: (minval, maxval, probability)\n","ROTATE = (20, 0.5) # @params: (maxangle, probability)\n","RANDOM_CROP = (32, 32, 0.0) # @params: (min_width, min_height, probability)\n","CUTOUT = ((4, 4), 4, 0.0) # @params: ((mask_dim0, mask_dim1), max_num_holes, probability)\n","BLUR = ([4, 4], 4, 0.0) # @params: ((filter_dim0, filter_dim1), sigma, probability)\n","\n","def random_rotate3D(voxel, limit=90, p=0.5):\n","    if tf.random.uniform(()) < p:\n","        angle = tf.random.uniform((), minval=-limit, maxval=limit,\n","                                  dtype=tf.int32)\n","        voxel['image'] = tfa.image.rotate(voxel['image'], tf.cast(angle,\n","                                                tf.float32)*(math.pi/180),\n","                                 interpolation='nearest',\n","                                 fill_mode='constant',\n","                                 fill_value=0.0)\n","    return voxel['image']\n","\n","def random_resized_crop3D(voxel, min_width, min_height, p=0.5):\n","    if tf.random.uniform(()) < p:\n","        voxel_shape = voxel['image'].shape\n","        assert voxel_shape[1] >= min_height\n","        assert voxel_shape[2] >= min_width\n","        \n","        width = tf.random.uniform((), minval=min_width,\n","                                  maxval=voxel_shape[2],\n","                                  dtype=tf.int32)\n","        height = tf.random.uniform((), minval=min_height,\n","                                   maxval=voxel_shape[1],\n","                                   dtype=tf.int32)\n","        x = tf.random.uniform((), minval=0,\n","                              maxval=voxel_shape[2] - width,\n","                              dtype=tf.int32)\n","        y = tf.random.uniform((), minval=0,\n","                              maxval=voxel_shape[1] - height,\n","                              dtype=tf.int32)\n","        voxel['image'] = voxel['image'][:, y:y+height, x:x+width, :]\n","        voxel['image'] = tf.image.resize(voxel['image'],\n","                                voxel_shape[1:3],\n","                                method='lanczos5')\n","    return voxel['image']\n","\n","def random_cutout3D(voxel, mask_shape=(10, 10), num_holes=20, p=0.5):\n","    if tf.random.uniform(()) < p:\n","        voxel_shape = voxel['image'].shape\n","        assert voxel_shape[1] >= mask_shape[0]\n","        assert voxel_shape[2] >= mask_shape[1]\n","\n","        holes = tf.random.uniform((), minval=1, maxval=num_holes,\n","                                  dtype=tf.int32)\n","        mask_size = tf.constant([mask_shape[0], mask_shape[1]])\n","        mask = tf.Variable((lambda : tf.ones(voxel_shape)),\n","                           trainable=False)\n","        \n","        for i in tf.range(holes):\n","            x = tf.random.uniform((), minval=0,\n","                                  maxval=voxel_shape[2],\n","                                  dtype=tf.int32)\n","            y = tf.random.uniform((), minval=0,\n","                                  maxval=voxel_shape[1],\n","                                  dtype=tf.int32)\n","            mask_endx = tf.add(x, mask_size[1])\n","            mask_endy = tf.add(y, mask_size[0])\n","            mask[:, x:mask_endx,\n","                 y:mask_endy, :].assign(tf.zeros_like(mask[:, x:mask_endx,\n","                                                        y:mask_endy, :]))\n","        voxel['image'] = tf.multiply(voxel['image'], mask)\n","        mask.assign(tf.ones(voxel_shape))\n","    return voxel['image']\n","\n","def _get_gaussian_kernel(sigma, filter_shape):\n","    x = tf.range(-filter_shape // 2 + 1, filter_shape // 2 + 1)\n","    x = tf.cast(x ** 2, sigma.dtype)\n","    x = tf.nn.softmax(-x / (2.0 * (sigma ** 2)))\n","    return x\n","\n","def random_gaussian_blur3D(voxel, filter_shape=[5, 5], max_sigma=3, p=0.5):\n","    if tf.random.uniform(()) < p:\n","        sigma = tf.random.uniform((), minval=3, maxval=max_sigma,\n","                          dtype=tf.int32)\n","        filter_shape = tf.constant(filter_shape)\n","        channels = voxel['image'].shape[-1]\n","        sigma = tf.cast(sigma, voxel['image'].dtype)\n","        gaussian_kernel_x = _get_gaussian_kernel(sigma,\n","                                                 filter_shape[1])\n","        gaussian_kernel_x = gaussian_kernel_x[tf.newaxis, :]\n","        gaussian_kernel_y = _get_gaussian_kernel(sigma,\n","                                                 filter_shape[0])        \n","        gaussian_kernel_y = gaussian_kernel_y[:, tf.newaxis]\n","        gaussian_kernel_2d = tf.matmul(gaussian_kernel_y,\n","                                       gaussian_kernel_x)\n","        gaussian_kernel_2d = gaussian_kernel_2d[:, :, tf.newaxis,\n","                                                tf.newaxis]\n","        gaussian_kernel_2d = tf.tile(gaussian_kernel_2d,\n","                                     tf.constant([1, 1, channels, 1]))\n","        voxel['image'] = tf.nn.depthwise_conv2d(input=voxel['image'],\n","                                       filter=gaussian_kernel_2d,\n","                                       strides=(1, 1, 1, 1),\n","                                       padding=\"SAME\",\n","                                       )\n","        voxel['image'] = tf.cast(voxel['image'], voxel['image'].dtype)\n","    return voxel['image']\n","\n","def build_augmenter(with_labels=True):\n","    '''\n","    Performing tranformations with the same seed\n","    to ensure the same tranformation is applied to every voxel['image'] slice.\n","    ''' \n","    def augment(voxel):\n","        aug_seed = tf.random.uniform((2,), minval=1, maxval=9999, dtype=tf.int32)\n","        if tf.random.uniform(()) < FLIP:\n","            if tf.random.uniform(()) < 0.5:\n","                voxel['image'] = tf.image.flip_up_down(voxel['image'])\n","            else:\n","                voxel['image'] = tf.image.flip_left_right(voxel['image'])\n","                \n","        if tf.random.uniform(()) < BRIGHTNESS[1]:\n","            voxel['image'] = tf.image.adjust_brightness(\n","                voxel['image'], tf.random.uniform((), minval=0.0,\n","                                         maxval=BRIGHTNESS[0],\n","                                         seed=seed))\n","        if tf.random.uniform(()) < CONTRAST[2]:\n","            voxel['image'] = tf.image.adjust_contrast(\n","                voxel['image'], tf.random.uniform((), minval=CONTRAST[0],\n","                                         maxval=CONTRAST[1],\n","                                         seed=seed))\n","        if tf.random.uniform(()) < GAMMA[2]:\n","            voxel['image'] = tf.image.adjust_gamma(\n","                voxel['image'], tf.random.uniform((), minval=GAMMA[0],\n","                                         maxval=GAMMA[1],\n","                                         seed=seed))\n","        voxel['image'] = random_rotate3D(voxel, limit=ROTATE[0],\n","                                p=ROTATE[1])\n","        voxel['image'] = random_resized_crop3D(voxel, RANDOM_CROP[0],\n","                                      RANDOM_CROP[1],\n","                                      p=RANDOM_CROP[2])\n","        voxel['image'] = random_cutout3D(voxel, mask_shape=CUTOUT[0],\n","                                num_holes=CUTOUT[1],\n","                                p=CUTOUT[2])\n","        voxel['image'] = random_gaussian_blur3D(voxel,\n","                                       filter_shape=BLUR[0],\n","                                       max_sigma=BLUR[1],\n","                                       p=BLUR[2])\n","\n","        # Remove nans in place of black pixels in some imgs.\n","        # Anyone knows the reason for the nans?\n","        voxel['image'] = tf.where(tf.math.is_nan(voxel['image']),\n","                         tf.zeros_like(voxel['image']), voxel['image'])\n","        voxel['image'] = tnp.maximum(tnp.array([0.]), voxel['image'])\n","        voxel['image'] = tnp.minimum(tnp.array([1.]), voxel['image'])\n","        voxel['image'] = tf.cast(voxel['image'], tf.float32)\n","        return voxel\n","    \n","    def augment_with_labels(voxel, label):\n","        return augment(voxel), label\n","    \n","    return augment_with_labels if with_labels else augment"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:53.576528Z","iopub.status.busy":"2022-04-12T00:01:53.575743Z","iopub.status.idle":"2022-04-12T00:01:53.589933Z","shell.execute_reply":"2022-04-12T00:01:53.589247Z","shell.execute_reply.started":"2022-04-12T00:01:53.57648Z"},"trusted":true},"outputs":[],"source":["def load_dataset(filenames, ordered=False):\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False\n","    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE, compression_type=\"GZIP\")\n","    dataset = dataset.with_options(ignore_order)\n","    dataset = dataset.map(_parse_image_function, num_parallel_calls=AUTOTUNE)\n","    return dataset\n","\n","def load_testing_dataset(filenames, ordered=False):\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False\n","    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE, compression_type=\"GZIP\")\n","    dataset = dataset.with_options(ignore_order)\n","    dataset = dataset.map(_parse_image_function_testing, num_parallel_calls=AUTOTUNE)\n","    return dataset\n","\n","def get_training_dataset(dataset, do_aug=True, shuffleBuffer=2048):\n","\n","    AUTOTUNE = tf.data.experimental.AUTOTUNE\n","    \n","    if do_aug:\n","        augment_fn = build_augmenter(with_labels=True)\n","        dataset = dataset.map(augment_fn, num_parallel_calls=AUTOTUNE)\n","        \n","    dataset = dataset.repeat()\n","    dataset = dataset.shuffle(shuffleBuffer)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    \n","    return dataset\n","\n","def get_val_dataset(dataset, do_aug=False):\n","    if do_aug:\n","        pass\n","    dataset = dataset.batch(BATCH_SIZE)\n","#     dataset = dataset.cache()\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:53.591624Z","iopub.status.busy":"2022-04-12T00:01:53.591294Z","iopub.status.idle":"2022-04-12T00:01:54.014534Z","shell.execute_reply":"2022-04-12T00:01:54.013694Z","shell.execute_reply.started":"2022-04-12T00:01:53.591583Z"},"trusted":true},"outputs":[],"source":["from kaggle_datasets import KaggleDatasets\n","GCS_DS_PATH = KaggleDatasets().get_gcs_path('lidcidri-tfrecords8')\n","GCS_DS_PATH"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:54.016623Z","iopub.status.busy":"2022-04-12T00:01:54.015865Z","iopub.status.idle":"2022-04-12T00:01:54.25207Z","shell.execute_reply":"2022-04-12T00:01:54.251229Z","shell.execute_reply.started":"2022-04-12T00:01:54.016581Z"},"trusted":true},"outputs":[],"source":["train_tf_gcs = GCS_DS_PATH + '/train*.tfrec'\n","val_tf_gcs = GCS_DS_PATH +'/val*.tfrec'\n","train_tf_files = tf.io.gfile.glob(train_tf_gcs)\n","val_tf_files = tf.io.gfile.glob(val_tf_gcs)\n","# print(val_tf_files[:3])\n","print(\"Train TFrecord Files:\", len(train_tf_files))\n","print(\"Val TFrecord Files:\", len(val_tf_files))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:54.253876Z","iopub.status.busy":"2022-04-12T00:01:54.253472Z","iopub.status.idle":"2022-04-12T00:01:54.728401Z","shell.execute_reply":"2022-04-12T00:01:54.727489Z","shell.execute_reply.started":"2022-04-12T00:01:54.253833Z"},"trusted":true},"outputs":[],"source":["train_dataset = load_dataset(train_tf_files)\n","val_dataset = load_dataset(val_tf_files)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-11T14:58:27.71871Z","iopub.status.busy":"2022-04-11T14:58:27.718135Z","iopub.status.idle":"2022-04-11T14:58:30.994062Z","shell.execute_reply":"2022-04-11T14:58:30.992014Z","shell.execute_reply.started":"2022-04-11T14:58:27.718668Z"},"trusted":true},"outputs":[],"source":["# # del image, mask\n","# # gc.collect()\n","\n","# fig = plt.figure(figsize=(25, 25))\n","\n","for img, label in get_training_dataset(train_dataset, do_aug=False):\n","    plt.imshow(img['image'][50][0], cmap=plt.cm.gray)\n","    print(label)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-11T14:58:30.996022Z","iopub.status.busy":"2022-04-11T14:58:30.995709Z","iopub.status.idle":"2022-04-11T14:58:31.001344Z","shell.execute_reply":"2022-04-11T14:58:31.000476Z","shell.execute_reply.started":"2022-04-11T14:58:30.995981Z"},"trusted":true},"outputs":[],"source":["NUM_FILES = sum([int(file.split('/')[-1][-8:-6]) for file in train_tf_files])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:54.738761Z","iopub.status.busy":"2022-04-12T00:01:54.738498Z","iopub.status.idle":"2022-04-12T00:01:54.76703Z","shell.execute_reply":"2022-04-12T00:01:54.766302Z","shell.execute_reply.started":"2022-04-12T00:01:54.73872Z"},"trusted":true},"outputs":[],"source":["from classification_models_3D.tfkeras import Classifiers\n","\n","input_dict = ['image',\n","            'internalStructure',\n","            'calcification',\n","            'sphericity',\n","            'margin',\n","            'lobulation',\n","            'spiculation',\n","            'texture']\n","\n","def create_model(input_shape, num_classes, model_arch):\n","    \n","#     input_img = tf.keras.layers.Input((*input_shape, 1), name='image', dtype=tf.float32)\n","    \n","    inputs = {}\n","    for name in input_dict:\n","        if name == 'image':\n","            inputs[name] = tf.keras.layers.Input((*input_shape, 1), name='image', dtype=tf.float32)\n","        else:\n","            inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=tf.float32)\n","        \n","    numeric_inputs = {name: input_data for name, input_data in inputs.items() if name != 'image'}\n","    numeric_data = tf.keras.layers.Concatenate()(list(numeric_inputs.values()))\n","\n","    img_input = tf.keras.layers.Conv3D(3, (3, 3, 3), strides=(1, 1, 1), \n","                          padding='same', use_bias=True)(inputs['image'])\n","    \n","    net, preprocess_input = Classifiers.get(model_arch)\n","    x = net(input_shape=(*input_shape, 3), include_top=False,\n","                   weights='imagenet')(img_input)\n","    x = tf.keras.layers.GlobalAveragePooling3D()(x)\n","    x = tf.keras.layers.Dropout(rate=0.5)(x)\n","    \n","#     net2, preprocess_input = Classifiers.get('vgg16')\n","#     y = net2(input_shape=(*input_shape, 3), include_top=False,\n","#                    weights='imagenet')(img_input)\n","#     y = tf.keras.layers.GlobalAveragePooling3D()(y)\n","#     y = tf.keras.layers.Dropout(rate=0.5)(y)\n","    \n","    x = tf.keras.layers.Concatenate()([x, numeric_data])\n","#     x = tf.keras.layers.Dense(256, activation='relu')(x)\n","    \n","    # Cast output to float32 for numerical stability\n","    outputs = tf.keras.layers.Dense(num_classes, activation='softmax',\n","                                   dtype='float32')(x)\n","    model  = tf.keras.Model(inputs, outputs)\n","    model.summary()\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:54.768694Z","iopub.status.busy":"2022-04-12T00:01:54.76836Z","iopub.status.idle":"2022-04-12T00:01:54.779384Z","shell.execute_reply":"2022-04-12T00:01:54.778375Z","shell.execute_reply.started":"2022-04-12T00:01:54.768664Z"},"trusted":true},"outputs":[],"source":["class CategoricalFocalLossLabelSmoothing(tf.keras.losses.Loss):\n","    def __init__(self, gamma=2.0, alpha=0.25, ls=0.1, classes=5.0):\n","        super(CategoricalFocalLossLabelSmoothing, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.ls = ls\n","        self.classes = classes\n","        \n","    def focal_loss(self, y_true, y_pred, gamma, alpha, ls, classes):\n","        # Define epsilon so that the backpropagation will not result in NaN\n","        # for 0 divisor case\n","        epsilon = K.epsilon()\n","        # Add the epsilon to prediction value\n","        #y_pred = y_pred + epsilon\n","        #label smoothing\n","        y_pred_ls = (1 - ls) * y_pred + ls / classes\n","        # Clip the prediction value\n","        y_pred_ls = K.clip(y_pred_ls, epsilon, 1.0-epsilon)\n","        # Calculate cross entropy\n","        cross_entropy = -y_true*K.log(y_pred_ls)\n","        # Calculate weight that consists of  modulating factor and weighting factor\n","        weight = alpha * y_true * K.pow((1-y_pred_ls), gamma)\n","        # Calculate focal loss\n","        loss = weight * cross_entropy\n","        # Sum the losses in mini_batch\n","        loss = K.sum(loss, axis=1)\n","        return loss\n","        \n","    def call(self, y_true, y_pred):\n","        return self.focal_loss(y_true, y_pred, gamma=self.gamma, alpha=self.alpha, ls=self.ls, classes=self.classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:01:54.780864Z","iopub.status.busy":"2022-04-12T00:01:54.780621Z","iopub.status.idle":"2022-04-12T00:02:02.842359Z","shell.execute_reply":"2022-04-12T00:02:02.841437Z","shell.execute_reply.started":"2022-04-12T00:01:54.780835Z"},"trusted":true},"outputs":[],"source":["# BATCH_SIZE = 1\n","model_arch = 'vgg19'\n","EPOCHS = 50\n","STEPS_PER_EPOCH = 2104 // BATCH_SIZE\n","input_shape = (32, 64, 64)\n","with strategy.scope():\n","    model = create_model(input_shape, len(CLASSES), model_arch)\n","    \n","    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","        1e-3, decay_steps=10000, decay_rate=0.96, staircase=True\n","    )\n","    \n","    optimizer = tf.keras.optimizers.RMSprop(lr_schedule)#(1e-3)\n","#     loss = CategoricalFocalLossLabelSmoothing(gamma=1.5, alpha=0.1, ls=0.3, classes=5.0)\n","    loss = tf.keras.losses.CategoricalCrossentropy()\n","    metrics = [tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.AUC()]\n","    model.compile(optimizer, loss, metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-12T00:02:24.71335Z","iopub.status.busy":"2022-04-12T00:02:24.712965Z","iopub.status.idle":"2022-04-12T00:02:24.869644Z","shell.execute_reply":"2022-04-12T00:02:24.868703Z","shell.execute_reply.started":"2022-04-12T00:02:24.71331Z"},"trusted":true},"outputs":[],"source":["tf.keras.utils.plot_model(model, to_file=\"model.jpg\", rankdir='LR')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:58:35.912095Z","iopub.status.idle":"2022-04-11T14:58:35.912845Z","shell.execute_reply":"2022-04-11T14:58:35.912602Z","shell.execute_reply.started":"2022-04-11T14:58:35.912575Z"},"trusted":true},"outputs":[],"source":["START_LR = 1e-9\n","MAX_LR = 1e-4\n","MIN_LR = 1e-9\n","LR_RAMP = 5\n","LR_SUSTAIN = 3\n","LR_DECAY = 0.90\n","\n","def lrfn(epoch):\n","    if LR_RAMP > 0 and epoch < LR_RAMP:\n","        lr = (MAX_LR-START_LR)/(LR_RAMP*1.0)*epoch+START_LR\n","    elif epoch < LR_RAMP+LR_SUSTAIN:\n","        lr = MAX_LR\n","    else: # exponential decay from MAX_LR to MIN_LR\n","        lr = (MAX_LR-MIN_LR)*LR_DECAY**(epoch-LR_RAMP-LR_SUSTAIN)+MIN_LR\n","    return lr\n","    \n","@tf.function\n","def lrfn_tffun(epoch):\n","    return lrfn(epoch)\n","\n","fig = plt.figure(figsize=(14, 5))\n","ax = fig.add_subplot(111)\n","rng = [i for i in range(EPOCHS)]\n","plt.plot(rng, [lrfn(x) for x in rng],\n","         marker='o')\n","plt.ticklabel_format(axis=\"y\", style=\"plain\")\n","ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.1e'))\n","plt.show()\n","\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn_tffun(epoch), verbose=1)\n","\n","model_save = tf.keras.callbacks.ModelCheckpoint('./model.h5',\n","                             save_best_only = True, \n","                             monitor = 'val_categorical_accuracy', \n","                             mode = 'max', verbose = 1)\n","\n","early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=10, mode='max', verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:58:35.914172Z","iopub.status.idle":"2022-04-11T14:58:35.915333Z","shell.execute_reply":"2022-04-11T14:58:35.915081Z","shell.execute_reply.started":"2022-04-11T14:58:35.915053Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:58:35.916995Z","iopub.status.idle":"2022-04-11T14:58:35.917496Z","shell.execute_reply":"2022-04-11T14:58:35.917243Z","shell.execute_reply.started":"2022-04-11T14:58:35.917219Z"},"trusted":true},"outputs":[],"source":["history = model.fit(\n","    get_training_dataset(train_dataset, do_aug=True),\n","    steps_per_epoch = STEPS_PER_EPOCH,\n","    epochs = EPOCHS,\n","    callbacks = [model_save,\n","                 early_stop,\n","                ],\n","    validation_data = get_val_dataset(val_dataset),\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:58:35.918986Z","iopub.status.idle":"2022-04-11T14:58:35.919657Z","shell.execute_reply":"2022-04-11T14:58:35.919497Z","shell.execute_reply.started":"2022-04-11T14:58:35.919477Z"},"trusted":true},"outputs":[],"source":["with strategy.scope():\n","    model = tf.keras.models.load_model('./model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:58:35.920476Z","iopub.status.idle":"2022-04-11T14:58:35.921003Z","shell.execute_reply":"2022-04-11T14:58:35.920854Z","shell.execute_reply.started":"2022-04-11T14:58:35.920837Z"},"trusted":true},"outputs":[],"source":["# history.history\n","val_dataset = load_dataset(val_tf_files, ordered=True)\n","valds = get_val_dataset(val_dataset)\n","pred = model.predict(valds, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:58:35.921868Z","iopub.status.idle":"2022-04-11T14:58:35.922445Z","shell.execute_reply":"2022-04-11T14:58:35.922204Z","shell.execute_reply.started":"2022-04-11T14:58:35.922185Z"},"trusted":true},"outputs":[],"source":["imgs = []\n","labels = []\n","scan_ids = []\n","val_dataset = load_testing_dataset(val_tf_files, ordered=True)\n","for input_data, label in val_dataset.as_numpy_iterator():\n","    imgs.append(input_data['image'])\n","    labels.append(label)\n","    scan_ids.append(input_data['scan_id'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:58:35.926245Z","iopub.status.idle":"2022-04-11T14:58:35.926881Z","shell.execute_reply":"2022-04-11T14:58:35.926696Z","shell.execute_reply.started":"2022-04-11T14:58:35.926674Z"},"trusted":true},"outputs":[],"source":["history_frame = pd.DataFrame(history.history)\n","\n","fig = history_frame.loc[1:, ['loss', 'val_loss']].plot(title=\"Training and Validation Losses\", figsize=(20, 10), fontsize=15)\n","plt.legend([\"Training Loss\", \"Validation Loss\"], fontsize=15)\n","fig.axes.title.set_size(20)\n","plt.xlabel('Epochs', fontsize=18)\n","plt.savefig('losses.jpg')\n","\n","fig = history_frame.loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot(title=\"Training and Validation Accuracies\", xlabel=\"Epochs\", figsize=(20, 10), fontsize=15)\n","plt.legend([\"Training Accuracy\", \"Validation Accuracy\"], fontsize=15)\n","fig.axes.title.set_size(20)\n","plt.xlabel('Epochs', fontsize=18)\n","plt.savefig('accuracies.jpg')\n","\n","fig = history_frame.loc[:, ['auc_1', 'val_auc_1']].plot(title=\"Training and Validation AUC\", xlabel=\"Epochs\", figsize=(20, 10), fontsize=15)\n","plt.legend([\"Training AUC\", \"Validation AUC\"], fontsize=15)\n","fig.axes.title.set_size(20)\n","plt.xlabel('Epochs', fontsize=18)\n","plt.savefig('auc.jpg')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:58:35.927717Z","iopub.status.idle":"2022-04-11T14:58:35.928293Z","shell.execute_reply":"2022-04-11T14:58:35.928124Z","shell.execute_reply.started":"2022-04-11T14:58:35.928104Z"},"trusted":true},"outputs":[],"source":["tumor_id = 63\n","ncols = 4\n","nrows = 8\n","\n","f, plots = plt.subplots(nrows, ncols, figsize=(10, 25))\n","title = f.suptitle(f'{scan_ids[tumor_id].decode(\"utf-8\")}\\n Label: {labels[tumor_id].argmax() + 1} | Prediction: {pred[tumor_id].argmax() + 1}', fontsize='20', fontweight =\"bold\")\n","\n","i = 0\n","j = 0\n","\n","for index, ind in enumerate(imgs[tumor_id]):\n","    plots[i, j].axis('off')\n","    plots[i, j].set_title(f\"Slice Number: {index}\")\n","#     plots[i, j].imshow(img3d[ind], cmap=plt.cm.gray)\n","#     plots[i, j].imshow(masks[ind], alpha=0.5)\n","    plots[i, j].imshow(imgs[tumor_id][index], cmap=plt.cm.gray)\n","    j += 1\n","    if j % ncols == 0:\n","        i += 1\n","        j = 0\n","\n","title.set_y(1)\n","f.tight_layout()\n","plt.savefig(f'{scan_ids[tumor_id].decode(\"utf-8\")}.jpg')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
